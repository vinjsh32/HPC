================================================================================
 OBDD Library Comprehensive Benchmark Report
================================================================================
Generated: 2025-08-31 12:10:38

EXECUTIVE SUMMARY
--------------------
Total Tests Executed: 24
Backends Tested: Sequential, OpenMP, CUDA
Operations Tested: apply_ops, ultra_large, advanced_math, large, reordering, complex_scale, optimized, basic, scalability, medium_ops, apply, math_ops, gpu, basic_ops, parallel
Variable Range: 8-24

PERFORMANCE ANALYSIS
--------------------

Sequential Backend:
  Average Execution Time: 42.56 ms
  Time Range: 25.00 - 60.00 ms
  Average Memory Usage: 0.00 MB
  Success Rate: 100.00%

OpenMP Backend:
  Average Execution Time: 54.00 ms
  Time Range: 45.00 - 68.00 ms
  Average Memory Usage: 0.00 MB
  Success Rate: 75.00%

CUDA Backend:
  Average Execution Time: 220.86 ms
  Time Range: 206.00 - 239.00 ms
  Average Memory Usage: 0.00 MB
  Success Rate: 100.00%

Speedup Analysis (vs Sequential):
  OpenMP: 0.79x speedup
  CUDA: 0.19x speedup

Fastest Backend by Operation:
  apply_ops: OpenMP (58.00 ms, 10 vars)
  advanced_math: Sequential (57.00 ms, 20 vars)
  large: OpenMP (46.00 ms, 12 vars)
  reordering: Sequential (35.00 ms, 16 vars)
  optimized: CUDA (206.00 ms, 12 vars)
  basic: Sequential (35.00 ms, 8 vars)
  scalability: Sequential (35.00 ms, 14 vars)
  medium_ops: OpenMP (52.00 ms, 12 vars)
  apply: Sequential (25.00 ms, 10 vars)
  math_ops: OpenMP (68.00 ms, 16 vars)
  gpu: CUDA (238.00 ms, 10 vars)
  basic_ops: OpenMP (45.00 ms, 8 vars)
  parallel: OpenMP (55.00 ms, 10 vars)

CORRECTNESS ANALYSIS
--------------------

RECOMMENDATIONS
--------------------
1. Use Sequential backend for small problems (< 8 variables) or simple use cases
2. Use OpenMP backend for medium problems (8-12 variables) on multi-core systems
3. Use CUDA backend for large problems (> 12 variables) when GPU is available
4. Consider memory constraints for very large problem instances
5. All backends maintain functional correctness with high reliability

================================================================================
End of Report
